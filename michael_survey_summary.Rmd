---
title: "What to Do Before Fitting"
output: html_document
---

A document to summarize which variables we are interested in including in the model. All of you can make edits to the file/comment on whether my justification is appropriate. I did consider Melody's list before compiling these.

Essential idea is that I divide the variables into three groups: 1. Observed varaibles relating to subjective measure of alcohol consumption beliefs; 2. Observed variables relating to objective measure of alcohol consumption; 3. Demographic predictors to be adjusted for. 

1. and 2. consist of questions from Sections B and C, except a few that I think would not help us much with noisy measurements. I mainly skipped the questions in Section D, even though they must provide valuable information about the social network structure, simply to make our lives easier. Maybe you could add them in the analysis, given that we have enough time and resources. 

For 3., I excluded any variables that may be considerd "confounders," in that even if the survey questions mainly relate to demographics, they can still have substantial correlation with belief questions in their subjective phrasing. Also I tried to restrict my focus to variables that can be as accurately measured by this questionnaire as possible, as I want to place restrictions on how many latent layers our model will have before presentation. Many questions in Section F and G have thus been omitted. 

# 1. Subjective Questions

    - B1
    
    - B3
    
    - B4
    
    - B5
    
    - B7A ~ B7E.
    
    - B19
    
    - B21A ~ B21I.

# 2. Objective Questions

    - C1
    
    - C2
    
    - C3 ~ C6. Note these questions are for respondents who either responded >1 to C1 or to C2 (or both). Also, a separabe variable called C6_FEE exists for response 7 to C6.
    
    - C7
    
    - C9
    
    - C10
    
    - C11 ~ C15. Note these questions are for respondents who responded >3 for C10.
    
    - C16 is for respondents meeting the above condition + less than age 21 (A1 response < 21).
    
    - C17 ~ C21. Note these questions are for those who responded >2 for C10.
    
    - C22A ~ C22S.
    
# 3. Demographic Predictors

    - A1
    
    - A2
    
    - A3
    
    - A4. Note there is a sub-question A4A for responses 2 and 3.
    
    - A5
    
    - A6. Note there is a sub-question A6A for responses 5 and 6.
    
    - A7A ~ A7D.
    
    - A8A ~ A8I.
    
    - F5
    
    - G1
    
    - G2

    - G3 (Race: there exist respondents who chose multiple responses, even though the question asked to choose one.)
    
    - G4
    
    - G5A ~ G5B.
    
    - G7
    
    - G8
    
    - G13
    
    - G19A ~ E. (Whether a respondent has complete previous-year survey or not)

# Overview of Response rates
First, we may want to exclude from our sample those participants who have not responded to too many questions. Necessary adjustments are done to account for questions that allow multiple responses, or only target certain participants, etc, to obtain "true" missingness rates. The `missing_a` object refers to a binary matrix of missingness indices.

```{r, echo=FALSE}
cas01 <- read.csv("data/HarvardCAS01.csv")

#changed in my version dropped 4 and 7
sectionb_names <- c(paste0("B", c(1, 3, 5)), "B19",
                    colnames(cas01)[grepl("B21", colnames(cas01))])
sectionc_names <- c(paste0("C", c(1:2,7, 10:13)),
                    colnames(cas01)[grepl("C17", colnames(cas01))],
                    colnames(cas01)[grepl("C20", colnames(cas01))],
                    colnames(cas01)[grepl("C22", colnames(cas01))]
                    )
predictor_names <- c(paste0("A", 1:6), 
                     colnames(cas01)[grepl("A7", colnames(cas01))],
                     colnames(cas01)[grepl("A8", colnames(cas01))],
                     "F5", "G1", "G2",
                     colnames(cas01)[grepl("G3", colnames(cas01))], "G4",
                     colnames(cas01)[grepl("G5", colnames(cas01))],
                     "G7", "G8", "G13",
                     colnames(cas01)[grepl("G19", colnames(cas01))])[-11] # We don't want E29A7!

features <- cas01[,c(sectionb_names, sectionc_names, predictor_names)]
missing_a <- is.na(features)

# Corrections

missing_a[features$A1 >= 21 & !is.na(features$A1), colnames(features)[grepl("C16", colnames(features))]] <- FALSE

#missing_a[features$C1 == 1 & features$C2 == 1 & !is.na(features$C1) & !is.na(features$C1), c("C3", "C4", "C5", "C6")] <- FALSE

missing_a[features$C10 <= 3 & !is.na(features$C10),colnames(features)[grepl("C11", colnames(features))]] <- FALSE
missing_a[features$C10 <= 3 & !is.na(features$C10),colnames(features)[grepl("C12", colnames(features))]] <- FALSE
missing_a[features$C10 <= 3 & !is.na(features$C10),colnames(features)[grepl("C13", colnames(features))]] <- FALSE
missing_a[features$C10 <= 3 & !is.na(features$C10),colnames(features)[grepl("C14", colnames(features))]] <- FALSE
missing_a[features$C10 <= 3 & !is.na(features$C10),colnames(features)[grepl("C15", colnames(features))]] <- FALSE
missing_a[features$C10 <= 2 & !is.na(features$C10),colnames(features)[grepl("C17", colnames(features))]] <- FALSE
missing_a[features$C10 <= 2 & !is.na(features$C10),colnames(features)[grepl("C18", colnames(features))]] <- FALSE
missing_a[features$C10 <= 2 & !is.na(features$C10),colnames(features)[grepl("C19", colnames(features))]] <- FALSE
missing_a[features$C10 <= 2 & !is.na(features$C10),colnames(features)[grepl("C20", colnames(features))]] <- FALSE
missing_a[features$C10 <= 2 & !is.na(features$C10),colnames(features)[grepl("C21", colnames(features))]] <- FALSE

missing_a[apply(features[,grepl("A7", colnames(features))], 1, function(x) sum(is.na(x))) != 4, 
          grepl("A7", colnames(features))] <- FALSE

missing_a[apply(features[,grepl("G3", colnames(features))], 1, function(x) sum(is.na(x))) != 5, 
          grepl("G3", colnames(features))] <- FALSE

missing_a[apply(features[,grepl("G19", colnames(features))], 1, function(x) sum(is.na(x))) != 5, 
          grepl("G19", colnames(features))] <- FALSE

```

```{r}
hist(rowSums(missing_a), main = "Missing response per Participant")
```

It will be safe to exclude a number of participants who have filled out too few a questions on the survey based on the histogram.

Examining how many respones are missing for each of the questions, correcting for the fact that many questions ask only a part of the entire participants to respond.

```{r}
library(ggplot2)
df <- data.frame(names = colnames(missing_a), missing = c(colSums(missing_a)))
ggplot(df) + geom_col(aes(names, missing)) + 
    labs(x = NULL, title = "Missing response per Question")
```

It is both interesting and reasonable to recognize here that Question C16, which asks underage drinkers how they obtain alcohol, has the largest number of missing values.

Whatever responses that are in truth not missing should be informatively adjusted for by the model. E.g., if a participant did not answer to C16 simply because she is older than 21, maybe we should not include the predictor to begin with for a subset of the participants. __Any ideas on this__?

# Encoding of responses
To facilitate the interpretation of the model for ordinal variables, any response options that were not consistently coded are recoded in the following direction:

    * Section B: More stringent policy beliefs (Less) -> Lenient policy beliefs (More)
    
    * Section C: Less alcohol consumption (Less) -> More consumption (More)
    
Responses to questions B7, C3, C15, and C16 are categorical. For questions C20 and C22, direction of encoding is Not At All Important (less reliance) -> Very Important (more reliance).

```{r}
# B7. C3, C15, and C16 are categorical variables
features$B3 <- (5+1) - features$B3
#features$B4 <- (4+1) - features$B4
features$B5 <- as.integer(factor(features$B5, levels = c(4, 2, 1, 3)))
features$B19 <- (5+1) - features$B19
features[,grepl("C20", colnames(features))] <- apply(features[,grepl("C20", colnames(features))], 2, function(x) (4+1) - x)
#Shouldn't reverse direction here
#features[,grepl("C22", colnames(features))] <- apply(features[,grepl("C22", colnames(features))], 2, function(x) (4+1) - x)
```

I believe this should offer us all a common starting point.

# Model: What do we want to fit?

    1. Sub-divide the participants into different groups. This depends on which questions they had to answer in Section C. The groups will be
    
        i. < Age 21, drink in previous 30 days
        
        ii. >= Age 21, drink in previous 30 days
        
        iii. Drink in previous year (but not within prev. 30 days)
        
        iv. No drink in previous year
    
    A tricky situation happens if the participant did not respond to precisely those questions that allow us to classify her into one of the groups. We discard those cases for simplicity of the model.
    
    2. For now, fit a separate SEM model for each of the groups. 
    
        i. Exogenous variables are not "manifested," but rather directly observed, to keep the model fit under control. This means some imputation scheme is needed for the missing demographic variables.
        
        ii. Allow some correlation across questions conditional on the latent effects (factor scores). Especially for those questions which are really sub-questions.
        
        iii. Missing value should not really be a concern; if, however, computation is too taxing, we should be able to get away with some simple imputation scheme.
    
        iv. Include the 2001 sampling weights (not calibrated with the previous years' weights). The `lavaan` package states that it scales the weights if they do not sum up, but I think it will be safe to just scale them by myself manually when fitting different sub-population group models.
        
        v. Interpret what is actually going on (this is likely going to be challenging).

```{r pre_modeling}
# Subdividing the data into four groups
# Discards 38 people for whom we cannot obtain the info.
library(dplyr)
features$weights <- cas01$WEIGHT01 # Sampling weights are for cross-sectional study (see codebook)
group1 <- features %>% filter(A1 < 21, C10 > 3)
group2 <- features %>% filter(A1 >= 21, C10 > 3)
group3 <- features %>% filter(C10 == 3)
group4 <- features %>% filter(C10 < 3)
```

